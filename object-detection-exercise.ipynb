{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Create An Object Detection Solution\n",
    "\n",
    "In this notebook, you wrap up the **Create An Object Detection Solution** exercise by using the `CustomVisionPredictionClient` object found in the Azure Cognitive Services Python SDK.\n",
    "\n",
    "> **Important**: Several cells in this notebook contain `TODO` statements, where you need to update variables or enter code to enable the cell to execute without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the notebook\n",
    "\n",
    "### Install the Azure Cognitive Service Custom Vision Library\n",
    "\n",
    "To access the Custom Vision service from this Python notebook, you need to install the Azure Cognitive Services Custom Vision Library. This library is part of the [Azure SDK for Python](https://github.com/Azure/azure-sdk-for-python) GitHub project.\n",
    "\n",
    "> To learn more, read the [Azure Cognitive Services modules for Python](https://docs.microsoft.com/python/api/overview/azure/cognitive-services?view=azure-python) article in Microsoft Docs.\n",
    "\n",
    "Execute the cell below to install the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615247734000
    }
   },
   "outputs": [],
   "source": [
    "pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and services\n",
    "\n",
    "In addition to the Custom Vision library, we will also make use of a few other Python libraries in this notebook. Run the following cell to import the libraries and reference the services required to execute the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615247742016
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries need to call the classification service\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables\n",
    "\n",
    "To access your Custom Vision service, its `Project Id`, authentication `key` and `endpoint` URL need to be supplied to client applications.\n",
    "\n",
    "### Retrieve and set the Project Id\n",
    "\n",
    "`TODO`: Use the `Project Id` value found on the **Project Settings** page of the `Object Detector` project in the Custom Vision portal to replace the tokenized value for the `projectId` variable.\n",
    "\n",
    "- Retrieve the `Project Id` value  to replace the tokenized value for the `projectId` variable below.\n",
    "\n",
    "### Retrieve and set the `key` and `endpoint` values from your Custom Vision prediction service.\n",
    "\n",
    "`TODO`: Using the values from the `Keys and Endpoints` page for you Custom Vision prediction service, replace the tokenized values in the cell below, as follows:\n",
    "\n",
    "- Retrieve the `Key 1` value for your prediction cognitive services resource in the Azure portal and update the `key` value below.\n",
    "- Retrieve the `Endpoint` value for your prediction cognitive services resource in the Azure portal and update the `endpoint` value below.\n",
    "\n",
    "> **Important**: You **must** replace the variable values below with the values from your Custom Vision prediction endpoint or the remaining cells in this notebook will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615247782615
    }
   },
   "outputs": [],
   "source": [
    "# Update the values assigned to the variables below.\n",
    "projectId = 'not authorized to expose'\n",
    "key = 'not authorized to expose'\n",
    "endpoint = 'not authorized to expose'\n",
    "\n",
    "# The modelName variable's value must match the model name you set when you published the model!\n",
    "modelName = 'object-detection-exercise'\n",
    "print('Ready to detect objects using the model named \"{}\" from Custom Vision Project Id {}.'.format(modelName, projectId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Vision Prediction client\n",
    "\n",
    "After setting the `projectId`, `key` and `endpoint` needed to access your Custom Vision Prediction service, you can instantiate a client.\n",
    "\n",
    "`TODO`: In the cell below, locate the `TODO` statement and complete the `client = ` line to create a new Custom Vision Prediction Client object pointing to your Custom Vision prediction resource.\n",
    "\n",
    "Once you have updated the code, execute the cell below to create a `CustomVisionPredictionClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615248130075
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a Custom Vision Prediction client\n",
    "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": key})\n",
    "client = CustomVisionPredictionClient(endpoint=endpoint, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call your deployed object detection model\n",
    "\n",
    "The cell below uses a Custom Vision client to send images to your custom object detection model and returns the predictions made by the model.\n",
    "\n",
    "### Call the detect image method\n",
    "\n",
    "`TODO`: In the cell below, locate the `TODO` statement (after `results = client.`) and complete the line of code to call the `Detect Image` method of the `CustomVisionPredictionClient` object.\n",
    "\n",
    "> We covered this in the Object Detection demo, but if you need help, you can learn more by reading the [detect_image documentation](https://docs.microsoft.com/python/api/azure-cognitiveservices-vision-customvision/azure.cognitiveservices.vision.customvision.prediction.operations.customvisionpredictionclientoperationsmixin?view=azure-python#detect-image-project-id--published-name--image-data--application-none--custom-headers-none--raw-false----operation-config-).\n",
    "\n",
    "After completing the `TODO` line, execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Retrieve a test image from the 'test-images' folder\n",
    "testImagePath = os.path.join('test-images', 'silverware-test-02.jpg')\n",
    "testImage = Image.open(testImagePath)\n",
    "testImgHeight, testImgWidth, testImgCh = np.array(testImage).shape\n",
    "\n",
    "print('Detecting objects in {} using model {} in project {}...'.format(testImagePath, modelName, projectId))\n",
    "\n",
    "# Identify each object in the test image\n",
    "with open(testImagePath, mode=\"rb\") as imageData:\n",
    "    results = client.results = client.detect_image(projectId, modelName, imageData)\n",
    "    \n",
    "# Create a matplotlib figure to display the classification results\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "\n",
    "# Output the image with bounding boxes assigned to each detected entity\n",
    "draw = ImageDraw.Draw(testImage)\n",
    "lineWidth = int(np.array(testImage).shape[1]/100)\n",
    "\n",
    "object_colors = {\n",
    "    \"Fork\": \"lightblue\",\n",
    "    \"Knife\": \"yellow\",\n",
    "    \"Spoon\": \"orange\"\n",
    "}\n",
    "\n",
    "for prediction in results.predictions:\n",
    "    color = 'white' # default for 'other' object tags\n",
    "    if (prediction.probability*100) > 50:\n",
    "        if prediction.tag_name in object_colors:\n",
    "            color = object_colors[prediction.tag_name]\n",
    "        left = prediction.bounding_box.left * testImgWidth \n",
    "        top = prediction.bounding_box.top * testImgHeight \n",
    "        height = prediction.bounding_box.height * testImgHeight\n",
    "        width =  prediction.bounding_box.width * testImgWidth\n",
    "        points = ((left,top), (left+width,top), (left+width,top+height), (left,top+height),(left,top))\n",
    "        draw.line(points, fill=color, width=lineWidth)\n",
    "        plt.annotate(prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100),(left,top), backgroundcolor=color)\n",
    "plt.imshow(testImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
